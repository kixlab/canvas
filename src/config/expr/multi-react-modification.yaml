agent_type: react_modification

benchmark_dir: ../dataset/benchmarks/modification_gt
results_dir: ../dataset/results/modification_gen
batches_config_path: ../dataset/batches/modification/batches.yaml

channels:
  channel_1:
    api_base_url: http://localhost:3001
  channel_2:
    api_base_url: http://localhost:3002
  channel_3:
    api_base_url: http://localhost:3002
  channel_4:
    api_base_url: http://localhost:3003
  channel_5:
    api_base_url: http://localhost:3004
  channel_6:
    api_base_url: http://localhost:3005
  channel_7:
    api_base_url: http://localhost:3006

models:
  gpt-4o:
    provider: openai
    name: gpt-4o-2024-08-06
    temperature: 0.0
    input_cost: 0.0025
    output_cost: 0.0125
    max_turns: 50
    max_tokens: 2048
  gpt-4.1:
    provider: openai
    name: gpt-4.1-2025-04-14
    temperature: 0.0
    input_cost: 0.002 ## Cost per 1k input tokens
    output_cost: 0.008 ## Cost per 1k output tokens
    max_turns: 50
    max_tokens: 2048
  gpt-4o-mini:
    provider: openai
    name: gpt-4o-mini-2024-07-18
    temperature: 0.0
    input_cost: 0.00015
    output_cost: 0.0006
    max_turns: 50
    max_tokens: 2048
  o3:
    provider: openai
    name: o3-mini-2024-07-18
    temperature: 0.0
    input_cost: 0.00015
    output_cost: 0.0006
    max_turns: 50
    max_tokens: 2048
  claude-3-5-sonnet:
    provider: anthropic
    name: "anthropic.claude-3-5-sonnet-20241022-v2:0"
    temperature: 0.0
    input_cost: 0.003
    output_cost: 0.015
    max_turns: 50
    max_tokens: 2048
  gemini-2.5-flash:
    provider: google
    name: "models/gemini-2.5-flash"
    temperature: 0.0
    input_cost: 0.0003 ## Cost per 1k input tokens
    output_cost: 0.0025 ## Cost per 1k output tokens
    max_turns: 50
    max_tokens: 2048
  gemini-2.5-pro:
    provider: google
    name: "models/gemini-2.5-pro"
    temperature: 0.0
    input_cost: 0.00125 ## Cost per 1k input tokens
    output_cost: 0.01 ## Cost per 1k output tokens
    max_turns: 50
    max_tokens: 2048
  llama-4-maverick:
    provider: together
    name: "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
    temperature: 0.7
    input_cost: 0.0027
    output_cost: 0.0085
    max_turns: 50
    max_tokens: 2048
  llama-4-scout:
    provider: together
    name: "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
    temperature: 0.0
    input_cost: 0.0018
    output_cost: 0.0059
    max_turns: 50
    max_tokens: 2048